include:
  - remote: 'https://gitlab.com/cscs-ci/recipes/-/raw/master/templates/v2/.ci-ext.yml'

stages:
  - baseimage
  - build
  - test

build base cuda image:
  extends: .container-builder-dynamic-name
  stage: baseimage
  timeout: 2h
  variables:
    DOCKERFILE: ci/baseimage.cuda.Dockerfile
    WATCH_FILECHANGES: ci/baseimage.cuda.Dockerfile
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/base/sirius-ci
    DOCKER_BUILD_ARGS: '["CUDA_ARCH=60"]'

build base rocm image:
  extends: .container-builder-dynamic-name
  stage: baseimage
  # rocm takes long to build
  timeout: 4h
  variables:
    DOCKERFILE: ci/baseimage.rocm.Dockerfile
    WATCH_FILECHANGES: ci/baseimage.rocm.Dockerfile
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/base/sirius-ci
    DOCKER_BUILD_ARGS: '["ROCM_ARCH=gfx90a"]'

build cuda image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/sirius/sirius-ci:$CI_COMMIT_SHA
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +fortran +tests +apps +cuda +scalapack ^mpich ^spfft+single_precision+cuda ^intel-oneapi-mkl+cluster ^umpire+cuda~device_alloc'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build rocm image:
  extends: .container-builder
  needs: ["build base rocm image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: discard
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo ~fortran+tests +apps +rocm +scalapack ^mpich ^openblas ^umpire+rocm~device_alloc'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build elpa cuda image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: discard
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +tests +apps +cuda +scalapack +elpa ^mpich ^intel-oneapi-mkl+cluster ^elpa+cuda ^spfft+single_precision+cuda ^umpire+cuda~device_alloc'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build sequential eigen-solver cuda image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: discard
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +tests +apps +cuda +magma ^mpich ^openblas ^magma+cuda ^umpire+cuda~device_alloc'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build fp32 cuda image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: discard
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +fortran +tests +apps +cuda +scalapack +single_precision ^mpich ^intel-oneapi-mkl+cluster ^umpire+cuda~device_alloc'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build vdwxc cuda image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: discard
    # we can't use MKL here because vdwxc needs parallel FFT and MKL doesn't provide it
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +fortran +tests +apps +cuda +scalapack +vdwxc ^mpich ^openblas ^umpire+cuda~device_alloc'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build nlcg image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: discard
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +fortran +tests +apps +vdwxc +cuda +nlcglib ^openblas ^mpich ^nlcglib +cuda  ^umpire+cuda~device_alloc'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build clang image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: discard
    # reuse openblas, libxc and spfft from gcc build
    SPEC: 'sirius@develop %clang build_type=RelWithDebInfo ~fortran +tests ^openblas%gcc ^libxc%gcc ^mpich%gcc ^umpire~cuda~device_alloc'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build openmpi image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: discard
    SPEC: 'sirius@develop %gcc +tests +apps +scalapack +fortran build_type=RelWithDebInfo ^openblas ^openmpi ^umpire~cuda~device_alloc'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

.run_tests:
  extends: .container-runner-daint-gpu
  needs: ["build cuda image"]
  stage: test
  script:
    - cd /sirius-src/spack-build
    - |
      if [ "$SLURM_PROCID" == "0" ]; then
        $TEST_COMMAND -V
      else
        $TEST_COMMAND --output-on-failure
      fi
  image: $CSCS_REGISTRY_PATH/sirius/sirius-ci:$CI_COMMIT_SHA
  variables:
    CRAY_CUDA_MPS: 1
    GIT_STRATEGY: none
    MPICH_MAX_THREAD_SAFETY: multiple
    CSCS_REGISTRY_LOGIN: 'YES'
    PULL_IMAGE: 'YES'
    SLURM_HINT: nomultithread
    SLURM_JOB_NUM_NODES: 1
    SLURM_UNBUFFEREDIO: ''
    SLURM_WAIT: 0

gpu serial:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 12
    SLURM_CONSTRAINT: gpu
    SLURM_CPUS_PER_TASK: 12
    SLURM_NTASKS: 1
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L gpu_serial

gpu band parallel:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 3
    SLURM_CONSTRAINT: gpu
    SLURM_CPUS_PER_TASK: 3
    SLURM_NTASKS: 4
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L gpu_band_parallel
    USE_MPI: 'YES'

gpu k-point parallel:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 3
    SLURM_CONSTRAINT: gpu
    SLURM_CPUS_PER_TASK: 3
    SLURM_NTASKS: 4
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L gpu_k_point_parallel
    USE_MPI: 'YES'

cpu single:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 12
    SLURM_CONSTRAINT: gpu
    SLURM_CPU_BIND: sockets
    SLURM_CPUS_PER_TASK: 12
    SLURM_NTASKS: 1
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L cpu_serial

cpu band parallel:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 3
    SLURM_CONSTRAINT: gpu
    SLURM_CPU_BIND: sockets
    SLURM_CPUS_PER_TASK: 3
    SLURM_NTASKS: 4
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L cpu_band_parallel
    USE_MPI: 'YES'
