include:
  - remote: 'https://gitlab.com/cscs-ci/recipes/-/raw/master/templates/v2/.ci-ext.yml'

stages:
  - baseimage
  - build
  - test

build base cuda image:
  extends: .container-builder
  stage: baseimage
  # we create a tag that depends on the SHA value of ci/baseimage.cuda.Dockerfile, this way
  # a new base image is only built when the SHA of this file changes
  # If there are more dependency files that should change the tag-name of the base container
  # image, they can be added too.
  # Since the base image name is runtime dependent, we need to carry the value of it to
  # the following jobs via a dotenv file.
  before_script:
  - DOCKER_TAG=`sha256sum ci/baseimage.cuda.Dockerfile | head -c 16`
  - export PERSIST_IMAGE_NAME=$CSCS_REGISTRY_PATH/base/sirius-ci:$DOCKER_TAG
  - echo "BASE_IMAGE=$PERSIST_IMAGE_NAME" >> build.env
  artifacts:
    reports:
      dotenv: build.env
  variables:
    DOCKERFILE: ci/baseimage.cuda.Dockerfile
    # change to 'always' if you want to rebuild, even if target tag exists already (if-not-exists is the default, i.e. we could also skip the variable)
    CSCS_REBUILD_POLICY: if-not-exists
    DOCKER_BUILD_ARGS: '["CUDA_ARCH=60"]'

build base rocm image:
  extends: .container-builder
  stage: baseimage
  # rocm takes long to build
  timeout: 4h
  # we create a tag that depends on the SHA value of ci/baseimage.rocm.Dockerfile, this way
  # a new base image is only built when the SHA of this file changes
  # If there are more dependency files that should change the tag-name of the base container
  # image, they can be added too.
  # Since the base image name is runtime dependent, we need to carry the value of it to
  # the following jobs via a dotenv file.
  before_script:
  - DOCKER_TAG=`sha256sum ci/baseimage.rocm.Dockerfile | head -c 16`
  - export PERSIST_IMAGE_NAME=$CSCS_REGISTRY_PATH/base/sirius-ci:$DOCKER_TAG
  - echo "BASE_IMAGE=$PERSIST_IMAGE_NAME" >> build.env
  artifacts:
    reports:
      dotenv: build.env
  variables:
    DOCKERFILE: ci/baseimage.rocm.Dockerfile
    # change to 'always' if you want to rebuild, even if target tag exists already (if-not-exists is the default, i.e. we could also skip the variable)
    CSCS_REBUILD_POLICY: if-not-exists
    DOCKER_BUILD_ARGS: '["ROCM_ARCH=gfx90a"]'

build cuda image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/sirius/sirius-ci:$CI_COMMIT_SHA
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +fortran +tests +apps +cuda +scalapack +vdwxc ^mpich ^intel-oneapi-mkl+cluster'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build rocm image:
  extends: .container-builder
  needs: ["build base rocm image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/sirius/sirius-ci-rocm:$CI_COMMIT_SHA
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo ~fortran+tests +apps +rocm +scalapack ^mpich ^openblas'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build elpa cuda image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/sirius/sirius-ci:$CI_COMMIT_SHA
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +tests +apps +cuda +scalapack +elpa ^mpich ^intel-oneapi-mkl+cluster ^elpa+cuda'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build sequential eigen-solver cuda image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/sirius/sirius-ci:$CI_COMMIT_SHA
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +tests +apps +cuda +magma ^mpich ^intel-oneapi-mkl+cluster ^magma+cuda'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

build cuda fp32 image:
  extends: .container-builder
  needs: ["build base cuda image"]
  stage: build
  variables:
    DOCKERFILE: ci/build.Dockerfile
    PERSIST_IMAGE_NAME: $CSCS_REGISTRY_PATH/sirius/sirius-ci:$CI_COMMIT_SHA
    SPEC: 'sirius@develop %gcc build_type=RelWithDebInfo +fortran +tests +apps +cuda +scalapack +vdwxc +single_precision ^mpich ^intel-oneapi-mkl+cluster'
    DOCKER_BUILD_ARGS: '["BASE_IMAGE=${BASE_IMAGE}", "SPECDEV=$SPEC"]'

.run_tests:
  extends: .container-runner-daint-gpu
  needs: ["build cuda image"]
  stage: test
  script:
    - cd /sirius-src/spack-build
    - |
      if [ "$SLURM_PROCID" == "0" ]; then
        $TEST_COMMAND -V
      else
        $TEST_COMMAND --output-on-failure
      fi
  image: $CSCS_REGISTRY_PATH/sirius/sirius-ci:$CI_COMMIT_SHA
  variables:
    CRAY_CUDA_MPS: 1
    GIT_STRATEGY: none
    MPICH_MAX_THREAD_SAFETY: multiple
    CSCS_REGISTRY_LOGIN: 'YES'
    PULL_IMAGE: 'YES'
    SLURM_HINT: nomultithread
    SLURM_JOB_NUM_NODES: 1
    SLURM_UNBUFFEREDIO: ''
    SLURM_WAIT: 0

gpu serial:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 12
    SLURM_CONSTRAINT: gpu
    SLURM_CPUS_PER_TASK: 12
    SLURM_NTASKS: 1
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L gpu_serial

gpu band parallel:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 3
    SLURM_CONSTRAINT: gpu
    SLURM_CPUS_PER_TASK: 3
    SLURM_NTASKS: 4
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L gpu_band_parallel
    USE_MPI: 'YES'

gpu k-point parallel:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 3
    SLURM_CONSTRAINT: gpu
    SLURM_CPUS_PER_TASK: 3
    SLURM_NTASKS: 4
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L gpu_k_point_parallel
    USE_MPI: 'YES'

cpu single:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 12
    SLURM_CONSTRAINT: gpu
    SLURM_CPU_BIND: sockets
    SLURM_CPUS_PER_TASK: 12
    SLURM_NTASKS: 1
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L cpu_serial

cpu band parallel:
  extends: .run_tests
  variables:
    OMP_NUM_THREADS: 3
    SLURM_CONSTRAINT: gpu
    SLURM_CPU_BIND: sockets
    SLURM_CPUS_PER_TASK: 3
    SLURM_NTASKS: 4
    SLURM_TIMELIMIT: "30:00"
    TEST_COMMAND: ctest -L cpu_band_parallel
    USE_MPI: 'YES'
